{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import fastmri\n",
    "import fastmri.data.transforms as T\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "from fastmri.data import SliceDataset\n",
    "from fastmri.models import VarNet\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = '/scratch/svangurp/samuel/pretrained/knee/varnet/knee_leaderboard_state_dict.pt'\n",
    "# batch = does this model expect a cetrain kind of masking?\n",
    "# device ???\n",
    "\n",
    "# challange either multicoil or singe coil? what \n",
    "# state_dict_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h]\n",
      "                             [--challenge {varnet_knee_mc,varnet_brain_mc}]\n",
      "                             [--device DEVICE]\n",
      "                             [--state_dict_file STATE_DICT_FILE] --data_path\n",
      "                             DATA_PATH --output_path OUTPUT_PATH\n",
      "ipykernel_launcher.py: error: the following arguments are required: --data_path, --output_path\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/svangurp/envs/fastMRI/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3445: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def run_varnet_model(batch, model, device):\n",
    "    masked_kspace, mask, _, fname, slice_num, _, crop_size = batch\n",
    "    crop_size = crop_size[0]  # always have a batch size of 1 for varnet\n",
    "\n",
    "    output = model(masked_kspace.to(device), mask.to(device)).cpu()\n",
    "\n",
    "    # detect FLAIR 203\n",
    "    if output.shape[-1] < crop_size[1]:\n",
    "        crop_size = (output.shape[-1], output.shape[-1])\n",
    "\n",
    "    output = T.center_crop(output, crop_size)[0]\n",
    "\n",
    "    return output, int(slice_num[0]), fname[0]\n",
    "\n",
    "\n",
    "def run_inference(challenge, state_dict_file, data_path, output_path, device):\n",
    "    model = VarNet(num_cascades=12, pools=4, chans=18, sens_pools=4, sens_chans=8)\n",
    "    # download the state_dict if we don't have it\n",
    "    if state_dict_file is None:\n",
    "        if not Path(MODEL_FNAMES[challenge]).exists():\n",
    "            url_root = VARNET_FOLDER\n",
    "            download_model(url_root + MODEL_FNAMES[challenge], MODEL_FNAMES[challenge])\n",
    "\n",
    "        state_dict_file = MODEL_FNAMES[challenge]\n",
    "\n",
    "    model.load_state_dict(torch.load(state_dict_file))\n",
    "    model = model.eval()\n",
    "\n",
    "    # data loader setup\n",
    "    data_transform = T.VarNetDataTransform()\n",
    "    dataset = SliceDataset(\n",
    "        root=data_path, transform=data_transform, challenge=\"multicoil\"\n",
    "    )\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, num_workers=4)\n",
    "\n",
    "    # run the model\n",
    "    start_time = time.perf_counter()\n",
    "    outputs = defaultdict(list)\n",
    "    model = model.to(device)\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Running inference\"):\n",
    "        with torch.no_grad():\n",
    "            output, slice_num, fname = run_varnet_model(batch, model, device)\n",
    "\n",
    "        outputs[fname].append((slice_num, output))\n",
    "\n",
    "    # save outputs\n",
    "    for fname in outputs:\n",
    "        outputs[fname] = np.stack([out for _, out in sorted(outputs[fname])])\n",
    "\n",
    "    fastmri.save_reconstructions(outputs, output_path / \"reconstructions\")\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    print(f\"Elapsed time for {len(dataloader)} slices: {end_time-start_time}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--challenge\",\n",
    "        default=\"varnet_knee_mc\",\n",
    "        choices=(\n",
    "            \"varnet_knee_mc\",\n",
    "            \"varnet_brain_mc\",\n",
    "        ),\n",
    "        type=str,\n",
    "        help=\"Model to run\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\",\n",
    "        default=\"cuda\",\n",
    "        type=str,\n",
    "        help=\"Model to run\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--state_dict_file\",\n",
    "        default=None,\n",
    "        type=Path,\n",
    "        help=\"Path to saved state_dict (will download if not provided)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_path\",\n",
    "        type=Path,\n",
    "        required=True,\n",
    "        help=\"Path to subsampled data\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output_path\",\n",
    "        type=Path,\n",
    "        required=True,\n",
    "        help=\"Path for saving reconstructions\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    run_inference(\n",
    "        args.challenge,\n",
    "        args.state_dict_file,\n",
    "        args.data_path,\n",
    "        args.output_path,\n",
    "        torch.device(args.device),\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
