{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bb97401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import fastmri\n",
    "import fastmri.data.transforms as T\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "from fastmri.data import SliceDataset\n",
    "from fastmri.models import Unet\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a3e0cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading  multi coil knee file \n",
    "\n",
    "fname = '/scratch/svangurp/samuel/data/knee/train/file1000002.h5'\n",
    "data = h5py.File(fname, 'r')\n",
    "kspace = data[\"kspace\"][()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d6fd2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_unet_model(batch, model, device):\n",
    "    image, _, mean, std, fname, slice_num, _ = batch\n",
    "\n",
    "    output = model(image.to(device).unsqueeze(1)).squeeze(1).cpu()\n",
    "\n",
    "    mean = mean.unsqueeze(1).unsqueeze(2)\n",
    "    std = std.unsqueeze(1).unsqueeze(2)\n",
    "    output = (output * std + mean).cpu()\n",
    "\n",
    "    return output, int(slice_num[0]), fname[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35ade13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h]\n",
      "                             [--challenge {unet_knee_sc,unet_knee_mc,unet_brain_mc}]\n",
      "                             [--device DEVICE]\n",
      "                             [--state_dict_file STATE_DICT_FILE] --data_path\n",
      "                             DATA_PATH --output_path OUTPUT_PATH\n",
      "ipykernel_launcher.py: error: the following arguments are required: --data_path, --output_path\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "def run_inference(challenge, state_dict_file, data_path, output_path, device):\n",
    "    model = Unet(in_chans=1, out_chans=1, chans=256, num_pool_layers=4, drop_prob=0.0)\n",
    "    # download the state_dict if we don't have it\n",
    "    if state_dict_file is None:\n",
    "        if not Path(MODEL_FNAMES[challenge]).exists():\n",
    "            url_root = UNET_FOLDER\n",
    "            download_model(url_root + MODEL_FNAMES[challenge], MODEL_FNAMES[challenge])\n",
    "\n",
    "        state_dict_file = MODEL_FNAMES[challenge]\n",
    "\n",
    "    model.load_state_dict(torch.load(state_dict_file))\n",
    "    model = model.eval()\n",
    "\n",
    "    # data loader setup\n",
    "    if \"_mc\" in challenge:\n",
    "        data_transform = T.UnetDataTransform(which_challenge=\"multicoil\")\n",
    "    else:\n",
    "        data_transform = T.UnetDataTransform(which_challenge=\"singlecoil\")\n",
    "\n",
    "    if \"_mc\" in challenge:\n",
    "        dataset = SliceDataset(\n",
    "            root=data_path,\n",
    "            transform=data_transform,\n",
    "            challenge=\"multicoil\",\n",
    "        )\n",
    "    else:\n",
    "        dataset = SliceDataset(\n",
    "            root=data_path,\n",
    "            transform=data_transform,\n",
    "            challenge=\"singlecoil\",\n",
    "        )\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, num_workers=4)\n",
    "\n",
    "    # run the model\n",
    "    start_time = time.perf_counter()\n",
    "    outputs = defaultdict(list)\n",
    "    model = model.to(device)\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Running inference\"):\n",
    "        with torch.no_grad():\n",
    "            output, slice_num, fname = run_unet_model(batch, model, device)\n",
    "\n",
    "        outputs[fname].append((slice_num, output))\n",
    "\n",
    "    # save outputs\n",
    "    for fname in outputs:\n",
    "        outputs[fname] = np.stack([out for _, out in sorted(outputs[fname])])\n",
    "\n",
    "    fastmri.save_reconstructions(outputs, output_path / \"reconstructions\")\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    print(f\"Elapsed time for {len(dataloader)} slices: {end_time-start_time}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--challenge\",\n",
    "        default=\"unet_knee_sc\",\n",
    "        choices=(\n",
    "            \"unet_knee_sc\",\n",
    "            \"unet_knee_mc\",\n",
    "            \"unet_brain_mc\",\n",
    "        ),\n",
    "        type=str,\n",
    "        help=\"Model to run\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\",\n",
    "        default=\"cuda\",\n",
    "        type=str,\n",
    "        help=\"Model to run\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--state_dict_file\",\n",
    "        default=None,\n",
    "        type=Path,\n",
    "        help=\"Path to saved state_dict (will download if not provided)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--data_path\",\n",
    "        type=Path,\n",
    "        required=True,\n",
    "        help=\"Path to subsampled data\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output_path\",\n",
    "        type=Path,\n",
    "        required=True,\n",
    "        help=\"Path for saving reconstructions\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    run_inference(\n",
    "        args.challenge,\n",
    "        args.state_dict_file,\n",
    "        args.data_path,\n",
    "        args.output_path,\n",
    "        torch.device(args.device),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5129ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63a41ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference: 100%|██████████| 1448/1448 [03:20<00:00,  7.21it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'mkdir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8e80f07ce42e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mrun_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchallenge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dict_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-5af49389a932>\u001b[0m in \u001b[0;36mrun_inference\u001b[0;34m(challenge, state_dict_file, data_path, output_path, device)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mfastmri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reconstructions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/fastMRI/fastmri/utils.py\u001b[0m in \u001b[0;36msave_reconstructions\u001b[0;34m(reconstructions, out_dir)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mbe\u001b[0m \u001b[0msaved\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \"\"\"\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mout_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecons\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreconstructions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'mkdir'"
     ]
    }
   ],
   "source": [
    "challenge = 'unet_knee_mc' \n",
    "state_dict_file ='/home/svangurp/scratch/samuel/pretrained/knee/unet/knee_mc_leaderboard_state_dict.pt'\n",
    "data_path = '/scratch/svangurp/samuel/data/knee/train/'\n",
    "output_path ='/home/svangurp/scratch/samuel/data/knee/model_ouputs/Unet_recon_knee_mc/'\n",
    "device = 'cuda' \n",
    "\n",
    "run_inference(challenge, state_dict_file, data_path, output_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aa0b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
